{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of extracting features from a pretrained neural network in Caffe using SkiCaffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SkiCaffe is a wrapper that provides a \"scikit-learn like\" API to pretrained networks such as those distributed in the [Caffe Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo) or elsewhere (such as [DeepDetect](http://www.deepdetect.com/applications/model/)). Basically, I wanted to use these pretrained models for extracting features, but also use the powerful pipelines of scikit-learn. Here we illustrate it's basic use for extracting features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skicaffe import SkiCaffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use SKiCaffe, we need Caffe so we have to specify where Caffe was installed. We assume that the installation of Caffe is the default one from [BVLC](https://github.com/BVLC/caffe). We specify the location of Caffe on our system with caffe_root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe_root = '/usr/local/caffe/'\n",
    "model_file = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "prototxt_file = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "\n",
    "DLmodel = SkiCaffe(caffe_root = caffe_root,\n",
    "                   model_prototxt_path = prototxt_file, \n",
    "                   model_trained_path = model_file, \n",
    "                   include_labels = True,\n",
    "                   return_type = \"pandasDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Scikit-learn parlance, SkiCaffe is an estimator, since it is meant for extracting features from images. Therefore SkiCaffe inherits from the [BaseEstimator](http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator) and [TransformerMixin](http://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin) classes. The two methods that we overwrite are the fit and transform methods. SkiCaffe is a bit unusual in that the input data that is transformed is not a numpy array X of shape [n_samples, n_features], but rather the input is a python list of image paths. SkiCaffe takes these image paths and \"transforms\" them by returning features that are derived from a pretrained neural net in Caffe. \n",
    "\n",
    "The fit method loads the specified pretrained network. The transform method takes the list of images paths and returns the image features extracted from a specific layer as a numpy array (or optionally a Pandas Data Frame).  \n",
    "\n",
    "To load the pretrained network, the fit method in SkiCaffe needs the paths for the following two files:\n",
    "- deploy.prototxt file: neural network definition file for prediction\n",
    "- caffemodel file: the trained neural network (for example, bvlc_googlenet.caffemodel)\n",
    "\n",
    "The current setup of SkiCaffe is very ImageNet centric, therefore other supporting files from the default installation of Caffe are used (see documentation for more details and change as needed). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained BVLC reference model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this example we will be using the BVLC reference model and specify the protxt file and trained caffemodel file. We \"fit\" the model by loading the pretrained network. We can also use the layer_sizes attribute of our model to see what the different layers and their sizes are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffe imported successfully\n",
      "Number of layers: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('data', (10, 3, 227, 227)),\n",
       " ('conv1', (10, 96, 55, 55)),\n",
       " ('pool1', (10, 96, 27, 27)),\n",
       " ('norm1', (10, 96, 27, 27)),\n",
       " ('conv2', (10, 256, 27, 27)),\n",
       " ('pool2', (10, 256, 13, 13)),\n",
       " ('norm2', (10, 256, 13, 13)),\n",
       " ('conv3', (10, 384, 13, 13)),\n",
       " ('conv4', (10, 384, 13, 13)),\n",
       " ('conv5', (10, 256, 13, 13)),\n",
       " ('pool5', (10, 256, 6, 6)),\n",
       " ('fc6', (10, 4096)),\n",
       " ('fc7', (10, 4096)),\n",
       " ('fc8', (10, 1000)),\n",
       " ('prob', (10, 1000))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DLmodel.fit()\n",
    "print 'Number of layers:', len(DLmodel.layer_sizes)\n",
    "DLmodel.layer_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify list of images and extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_paths = ['./images/cat.jpg', \n",
    "               './images/1404329745.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now \"transform\" these images by extracting their features from our pretrained network. All we have to do is specify the layer name (listed above). Here we select the output of the last fully connected layer \"fc8\". If you like Data Frames (like me), then you can optionally specify that the return type be a Pandas Data Frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred.class</th>\n",
       "      <th>pred.conf</th>\n",
       "      <th>fc8.0</th>\n",
       "      <th>fc8.1</th>\n",
       "      <th>fc8.2</th>\n",
       "      <th>fc8.3</th>\n",
       "      <th>fc8.4</th>\n",
       "      <th>fc8.5</th>\n",
       "      <th>fc8.6</th>\n",
       "      <th>fc8.7</th>\n",
       "      <th>...</th>\n",
       "      <th>fc8.990</th>\n",
       "      <th>fc8.991</th>\n",
       "      <th>fc8.992</th>\n",
       "      <th>fc8.993</th>\n",
       "      <th>fc8.994</th>\n",
       "      <th>fc8.995</th>\n",
       "      <th>fc8.996</th>\n",
       "      <th>fc8.997</th>\n",
       "      <th>fc8.998</th>\n",
       "      <th>fc8.999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02123045 tabby, tabby cat</td>\n",
       "      <td>0.301984</td>\n",
       "      <td>-3.951654</td>\n",
       "      <td>3.974992</td>\n",
       "      <td>-2.126802</td>\n",
       "      <td>-1.871261</td>\n",
       "      <td>-2.662160</td>\n",
       "      <td>-1.353720</td>\n",
       "      <td>-1.741305</td>\n",
       "      <td>0.325119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965206</td>\n",
       "      <td>-1.478447</td>\n",
       "      <td>-1.339074</td>\n",
       "      <td>-2.622084</td>\n",
       "      <td>-2.790083</td>\n",
       "      <td>-0.731835</td>\n",
       "      <td>-2.223104</td>\n",
       "      <td>-3.972739</td>\n",
       "      <td>3.412313</td>\n",
       "      <td>5.382214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n09472597 volcano</td>\n",
       "      <td>0.301601</td>\n",
       "      <td>-0.368596</td>\n",
       "      <td>-2.329629</td>\n",
       "      <td>-2.272709</td>\n",
       "      <td>-1.236161</td>\n",
       "      <td>0.337776</td>\n",
       "      <td>-1.146151</td>\n",
       "      <td>0.180243</td>\n",
       "      <td>-1.866235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175359</td>\n",
       "      <td>0.087868</td>\n",
       "      <td>-0.151791</td>\n",
       "      <td>-2.187589</td>\n",
       "      <td>-1.585882</td>\n",
       "      <td>1.581705</td>\n",
       "      <td>-1.362859</td>\n",
       "      <td>-0.552606</td>\n",
       "      <td>5.315578</td>\n",
       "      <td>-0.433723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred.class  pred.conf     fc8.0     fc8.1     fc8.2  \\\n",
       "0  n02123045 tabby, tabby cat   0.301984 -3.951654  3.974992 -2.126802   \n",
       "1           n09472597 volcano   0.301601 -0.368596 -2.329629 -2.272709   \n",
       "\n",
       "      fc8.3     fc8.4     fc8.5     fc8.6     fc8.7    ...      fc8.990  \\\n",
       "0 -1.871261 -2.662160 -1.353720 -1.741305  0.325119    ...     0.965206   \n",
       "1 -1.236161  0.337776 -1.146151  0.180243 -1.866235    ...     1.175359   \n",
       "\n",
       "    fc8.991   fc8.992   fc8.993   fc8.994   fc8.995   fc8.996   fc8.997  \\\n",
       "0 -1.478447 -1.339074 -2.622084 -2.790083 -0.731835 -2.223104 -3.972739   \n",
       "1  0.087868 -0.151791 -2.187589 -1.585882  1.581705 -1.362859 -0.552606   \n",
       "\n",
       "    fc8.998   fc8.999  \n",
       "0  3.412313  5.382214  \n",
       "1  5.315578 -0.433723  \n",
       "\n",
       "[2 rows x 1002 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features = DLmodel.transform(X = image_paths)\n",
    "image_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now  lets get the faetures again but this time from an earlier layer and have the features returned as a numpy array. We also do not care about the labels so we will not extract that either:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         4.88522577,  6.54640722],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DLmodel.include_labels = False\n",
    "DLmodel.return_type = 'numpy_array'\n",
    "image_features = DLmodel.transform(X = image_paths, layer_name='fc7')\n",
    "image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load pretrained ResNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get features using a different model. We will use a ResNet-50 model that we include in this repo as an example. In this example we will also ensure that the returned features DataFrame will have an \"image_paths\" column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe_root = '/usr/local/caffe/'\n",
    "model_file = './models/ResNet-50-model.caffemodel'\n",
    "prototxt_file = './models/ResNet-50-deploy.prototxt'\n",
    "\n",
    "ResNet = SkiCaffe(caffe_root = caffe_root,\n",
    "                  model_prototxt_path = prototxt_file, \n",
    "                  model_trained_path = model_file, \n",
    "                  include_labels = False,\n",
    "                  include_image_paths = True,\n",
    "                  return_type = \"pandasDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffe imported successfully\n",
      "Number of layers: 106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('data', (1, 3, 224, 224)),\n",
       " ('conv1', (1, 64, 112, 112)),\n",
       " ('pool1', (1, 64, 56, 56)),\n",
       " ('pool1_pool1_0_split_0', (1, 64, 56, 56)),\n",
       " ('pool1_pool1_0_split_1', (1, 64, 56, 56)),\n",
       " ('res2a_branch1', (1, 256, 56, 56)),\n",
       " ('res2a_branch2a', (1, 64, 56, 56)),\n",
       " ('res2a_branch2b', (1, 64, 56, 56)),\n",
       " ('res2a_branch2c', (1, 256, 56, 56)),\n",
       " ('res2a', (1, 256, 56, 56)),\n",
       " ('res2a_res2a_relu_0_split_0', (1, 256, 56, 56)),\n",
       " ('res2a_res2a_relu_0_split_1', (1, 256, 56, 56)),\n",
       " ('res2b_branch2a', (1, 64, 56, 56)),\n",
       " ('res2b_branch2b', (1, 64, 56, 56)),\n",
       " ('res2b_branch2c', (1, 256, 56, 56)),\n",
       " ('res2b', (1, 256, 56, 56)),\n",
       " ('res2b_res2b_relu_0_split_0', (1, 256, 56, 56)),\n",
       " ('res2b_res2b_relu_0_split_1', (1, 256, 56, 56)),\n",
       " ('res2c_branch2a', (1, 64, 56, 56)),\n",
       " ('res2c_branch2b', (1, 64, 56, 56)),\n",
       " ('res2c_branch2c', (1, 256, 56, 56)),\n",
       " ('res2c', (1, 256, 56, 56)),\n",
       " ('res2c_res2c_relu_0_split_0', (1, 256, 56, 56)),\n",
       " ('res2c_res2c_relu_0_split_1', (1, 256, 56, 56)),\n",
       " ('res3a_branch1', (1, 512, 28, 28)),\n",
       " ('res3a_branch2a', (1, 128, 28, 28)),\n",
       " ('res3a_branch2b', (1, 128, 28, 28)),\n",
       " ('res3a_branch2c', (1, 512, 28, 28)),\n",
       " ('res3a', (1, 512, 28, 28)),\n",
       " ('res3a_res3a_relu_0_split_0', (1, 512, 28, 28)),\n",
       " ('res3a_res3a_relu_0_split_1', (1, 512, 28, 28)),\n",
       " ('res3b_branch2a', (1, 128, 28, 28)),\n",
       " ('res3b_branch2b', (1, 128, 28, 28)),\n",
       " ('res3b_branch2c', (1, 512, 28, 28)),\n",
       " ('res3b', (1, 512, 28, 28)),\n",
       " ('res3b_res3b_relu_0_split_0', (1, 512, 28, 28)),\n",
       " ('res3b_res3b_relu_0_split_1', (1, 512, 28, 28)),\n",
       " ('res3c_branch2a', (1, 128, 28, 28)),\n",
       " ('res3c_branch2b', (1, 128, 28, 28)),\n",
       " ('res3c_branch2c', (1, 512, 28, 28)),\n",
       " ('res3c', (1, 512, 28, 28)),\n",
       " ('res3c_res3c_relu_0_split_0', (1, 512, 28, 28)),\n",
       " ('res3c_res3c_relu_0_split_1', (1, 512, 28, 28)),\n",
       " ('res3d_branch2a', (1, 128, 28, 28)),\n",
       " ('res3d_branch2b', (1, 128, 28, 28)),\n",
       " ('res3d_branch2c', (1, 512, 28, 28)),\n",
       " ('res3d', (1, 512, 28, 28)),\n",
       " ('res3d_res3d_relu_0_split_0', (1, 512, 28, 28)),\n",
       " ('res3d_res3d_relu_0_split_1', (1, 512, 28, 28)),\n",
       " ('res4a_branch1', (1, 1024, 14, 14)),\n",
       " ('res4a_branch2a', (1, 256, 14, 14)),\n",
       " ('res4a_branch2b', (1, 256, 14, 14)),\n",
       " ('res4a_branch2c', (1, 1024, 14, 14)),\n",
       " ('res4a', (1, 1024, 14, 14)),\n",
       " ('res4a_res4a_relu_0_split_0', (1, 1024, 14, 14)),\n",
       " ('res4a_res4a_relu_0_split_1', (1, 1024, 14, 14)),\n",
       " ('res4b_branch2a', (1, 256, 14, 14)),\n",
       " ('res4b_branch2b', (1, 256, 14, 14)),\n",
       " ('res4b_branch2c', (1, 1024, 14, 14)),\n",
       " ('res4b', (1, 1024, 14, 14)),\n",
       " ('res4b_res4b_relu_0_split_0', (1, 1024, 14, 14)),\n",
       " ('res4b_res4b_relu_0_split_1', (1, 1024, 14, 14)),\n",
       " ('res4c_branch2a', (1, 256, 14, 14)),\n",
       " ('res4c_branch2b', (1, 256, 14, 14)),\n",
       " ('res4c_branch2c', (1, 1024, 14, 14)),\n",
       " ('res4c', (1, 1024, 14, 14)),\n",
       " ('res4c_res4c_relu_0_split_0', (1, 1024, 14, 14)),\n",
       " ('res4c_res4c_relu_0_split_1', (1, 1024, 14, 14)),\n",
       " ('res4d_branch2a', (1, 256, 14, 14)),\n",
       " ('res4d_branch2b', (1, 256, 14, 14)),\n",
       " ('res4d_branch2c', (1, 1024, 14, 14)),\n",
       " ('res4d', (1, 1024, 14, 14)),\n",
       " ('res4d_res4d_relu_0_split_0', (1, 1024, 14, 14)),\n",
       " ('res4d_res4d_relu_0_split_1', (1, 1024, 14, 14)),\n",
       " ('res4e_branch2a', (1, 256, 14, 14)),\n",
       " ('res4e_branch2b', (1, 256, 14, 14)),\n",
       " ('res4e_branch2c', (1, 1024, 14, 14)),\n",
       " ('res4e', (1, 1024, 14, 14)),\n",
       " ('res4e_res4e_relu_0_split_0', (1, 1024, 14, 14)),\n",
       " ('res4e_res4e_relu_0_split_1', (1, 1024, 14, 14)),\n",
       " ('res4f_branch2a', (1, 256, 14, 14)),\n",
       " ('res4f_branch2b', (1, 256, 14, 14)),\n",
       " ('res4f_branch2c', (1, 1024, 14, 14)),\n",
       " ('res4f', (1, 1024, 14, 14)),\n",
       " ('res4f_res4f_relu_0_split_0', (1, 1024, 14, 14)),\n",
       " ('res4f_res4f_relu_0_split_1', (1, 1024, 14, 14)),\n",
       " ('res5a_branch1', (1, 2048, 7, 7)),\n",
       " ('res5a_branch2a', (1, 512, 7, 7)),\n",
       " ('res5a_branch2b', (1, 512, 7, 7)),\n",
       " ('res5a_branch2c', (1, 2048, 7, 7)),\n",
       " ('res5a', (1, 2048, 7, 7)),\n",
       " ('res5a_res5a_relu_0_split_0', (1, 2048, 7, 7)),\n",
       " ('res5a_res5a_relu_0_split_1', (1, 2048, 7, 7)),\n",
       " ('res5b_branch2a', (1, 512, 7, 7)),\n",
       " ('res5b_branch2b', (1, 512, 7, 7)),\n",
       " ('res5b_branch2c', (1, 2048, 7, 7)),\n",
       " ('res5b', (1, 2048, 7, 7)),\n",
       " ('res5b_res5b_relu_0_split_0', (1, 2048, 7, 7)),\n",
       " ('res5b_res5b_relu_0_split_1', (1, 2048, 7, 7)),\n",
       " ('res5c_branch2a', (1, 512, 7, 7)),\n",
       " ('res5c_branch2b', (1, 512, 7, 7)),\n",
       " ('res5c_branch2c', (1, 2048, 7, 7)),\n",
       " ('res5c', (1, 2048, 7, 7)),\n",
       " ('pool5', (1, 2048, 1, 1)),\n",
       " ('fc1000', (1, 1000)),\n",
       " ('prob', (1, 1000))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet.fit()\n",
    "print 'Number of layers:', len(ResNet.layer_sizes)\n",
    "ResNet.layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_paths</th>\n",
       "      <th>fc1000.0</th>\n",
       "      <th>fc1000.1</th>\n",
       "      <th>fc1000.2</th>\n",
       "      <th>fc1000.3</th>\n",
       "      <th>fc1000.4</th>\n",
       "      <th>fc1000.5</th>\n",
       "      <th>fc1000.6</th>\n",
       "      <th>fc1000.7</th>\n",
       "      <th>fc1000.8</th>\n",
       "      <th>...</th>\n",
       "      <th>fc1000.990</th>\n",
       "      <th>fc1000.991</th>\n",
       "      <th>fc1000.992</th>\n",
       "      <th>fc1000.993</th>\n",
       "      <th>fc1000.994</th>\n",
       "      <th>fc1000.995</th>\n",
       "      <th>fc1000.996</th>\n",
       "      <th>fc1000.997</th>\n",
       "      <th>fc1000.998</th>\n",
       "      <th>fc1000.999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./images/cat.jpg</td>\n",
       "      <td>-1.422729</td>\n",
       "      <td>1.202515</td>\n",
       "      <td>-4.054061</td>\n",
       "      <td>-2.982319</td>\n",
       "      <td>-2.029956</td>\n",
       "      <td>-0.502533</td>\n",
       "      <td>-1.860753</td>\n",
       "      <td>0.857842</td>\n",
       "      <td>1.985428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521646</td>\n",
       "      <td>0.397216</td>\n",
       "      <td>0.230053</td>\n",
       "      <td>0.05036</td>\n",
       "      <td>-1.623829</td>\n",
       "      <td>-1.071765</td>\n",
       "      <td>-0.017579</td>\n",
       "      <td>-0.923358</td>\n",
       "      <td>3.147756</td>\n",
       "      <td>4.903510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./images/1404329745.jpg</td>\n",
       "      <td>-0.560677</td>\n",
       "      <td>-1.725651</td>\n",
       "      <td>-0.995183</td>\n",
       "      <td>-0.201458</td>\n",
       "      <td>-0.613417</td>\n",
       "      <td>-2.232322</td>\n",
       "      <td>-0.607065</td>\n",
       "      <td>-1.143935</td>\n",
       "      <td>-2.150558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027323</td>\n",
       "      <td>-0.578616</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>-2.18331</td>\n",
       "      <td>-1.461334</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>-1.939194</td>\n",
       "      <td>-1.392281</td>\n",
       "      <td>0.628841</td>\n",
       "      <td>0.852022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_paths  fc1000.0  fc1000.1  fc1000.2  fc1000.3  fc1000.4  \\\n",
       "0         ./images/cat.jpg -1.422729  1.202515 -4.054061 -2.982319 -2.029956   \n",
       "1  ./images/1404329745.jpg -0.560677 -1.725651 -0.995183 -0.201458 -0.613417   \n",
       "\n",
       "   fc1000.5  fc1000.6  fc1000.7  fc1000.8     ...      fc1000.990  fc1000.991  \\\n",
       "0 -0.502533 -1.860753  0.857842  1.985428     ...        0.521646    0.397216   \n",
       "1 -2.232322 -0.607065 -1.143935 -2.150558     ...       -0.027323   -0.578616   \n",
       "\n",
       "   fc1000.992  fc1000.993  fc1000.994  fc1000.995  fc1000.996  fc1000.997  \\\n",
       "0    0.230053     0.05036   -1.623829   -1.071765   -0.017579   -0.923358   \n",
       "1    0.019842    -2.18331   -1.461334    0.499992   -1.939194   -1.392281   \n",
       "\n",
       "   fc1000.998  fc1000.999  \n",
       "0    3.147756    4.903510  \n",
       "1    0.628841    0.852022  \n",
       "\n",
       "[2 rows x 1001 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features = ResNet.transform(X = image_paths)\n",
    "image_features.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
